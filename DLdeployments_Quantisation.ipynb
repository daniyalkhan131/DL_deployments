{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ONifmjsy27Pg"
      },
      "outputs": [],
      "source": [
        "#though when we convert to onnx then model size reduce but now we will do quantisation to\n",
        "#make it run on edge devices\n",
        "\n",
        "#before stats\n",
        "# tf, gpu = 0.15s\n",
        "# tf, cpu = 0.8s\n",
        "# tf_size = 1000MB\n",
        "\n",
        "# onnx, cpu = 0.5s\n",
        "# onnx, gpu = 0.025s\n",
        "# onnx_size = 328MB\n",
        "\n",
        "# onnx_quantized, cpu = 0.4s\n",
        "# onnx_quantized, gpu = 0.3s\n",
        "# onnx_quantized_size = 83MB"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Flatten\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "from keras.applications import VGG16\n",
        "conv_base = VGG16(weights='imagenet',\n",
        "    include_top = False,\n",
        "    input_shape=(224,224,3))\n",
        "\n",
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "\n",
        "for layer in conv_base.layers:\n",
        "  #if layer.name == 'conv2d_81':\n",
        "  if layer.name=='input_1':\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False\n",
        "initializer = tensorflow.keras.initializers.HeNormal(seed=42)\n",
        "model = Sequential()\n",
        "\n",
        "model.add(conv_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='relu',kernel_initializer=initializer))\n",
        "model.add(Dense(128,activation='relu',kernel_initializer=initializer))\n",
        "model.add(Dense(2,activation='softmax',kernel_initializer=initializer))\n",
        "model.compile(\n",
        "    optimizer=tensorflow.keras.optimizers.SGD(learning_rate=0.001,momentum=0.9,nesterov=True,weight_decay=0.0005),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "import numpy as np\n",
        "X=np.random.normal(size=(10,224,224,3))\n",
        "y=np.array([1,0,1,1,0,0,1,1,0,0])\n",
        "\n",
        "history=model.fit(\n",
        "    X, y,\n",
        "    epochs=1,\n",
        "    batch_size=2\n",
        ")\n",
        "\n",
        "\n",
        "print(history.history['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obBzCdKM35ef",
        "outputId": "a89f137d-044a-4f74-c27b-24e37a35a53a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 29s 5s/step - loss: 1.3881 - accuracy: 0.5000\n",
            "[0.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U tf2onnx\n",
        "! pip install onnxruntime\n",
        "\n",
        "import tensorflow as tf\n",
        "import tf2onnx\n",
        "import onnxruntime as rt\n",
        "spec = (tf.TensorSpec(\n",
        "    (None,\n",
        "     224, #CONFIGURATION[ \"IM_SIZE\"],\n",
        "     224, #CONFIGURATION[\"IM_SIZE\"]\n",
        "     3), tf.float32, name=\"input\"),)\n",
        "\n",
        "output_path = \"vgg16_keras.onnx\"\n",
        "\n",
        "model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13, output_path=output_path)\n",
        "#opset tell about the version\n",
        "output_names = [n.name for n in model_proto.graph.output]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMp4rqe34Kmu",
        "outputId": "3fd49446-3507-42d8-86f0-52876e615048"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.16.1-py3-none-any.whl (455 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/455.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/455.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.8/455.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.25.2)\n",
            "Collecting onnx>=1.4.1 (from tf2onnx)\n",
            "  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (24.3.25)\n",
            "Requirement already satisfied: protobuf~=3.20 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (3.20.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2024.2.2)\n",
            "Installing collected packages: onnx, tf2onnx\n",
            "Successfully installed onnx-1.16.0 tf2onnx-1.16.1\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#qunatisation"
      ],
      "metadata": {
        "id": "h1VH1AyQ4f4l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "from onnxruntime.quantization import quantize_dynamic, QuantType"
      ],
      "metadata": {
        "id": "fU3AlDdQ3SzD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fp32 = '/content/vgg16_keras.onnx'\n",
        "model_quant = '/content/vgg16_keras_quantized.onnx'\n",
        "\n",
        "quantized_model = quantize_dynamic(model_fp32, model_quant, weight_type = QuantType.QUInt8)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0rvATDa5jsj",
        "outputId": "a0940853-98c8-401f-983e-a9e520da08fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#size reduced to 17mb only"
      ],
      "metadata": {
        "id": "OiAYY34q5tTy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inference\n",
        "\n",
        "\n",
        "import onnxruntime as rt\n",
        "\n",
        "output_path = \"/content/vgg16_keras_quantized.onnx\"\n",
        "providers = ['CPUExecutionProvider']\n",
        "\n",
        "m = rt.InferenceSession(output_path, providers=providers)\n",
        "\n",
        "im=np.random.normal(size=(3,224,224,3))\n",
        "im=np.float32(im)\n",
        "\n",
        "m.run(output_names, {\"input\": im})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKnEU5nU6Ep9",
        "outputId": "fea15fe4-3987-4a34-f742-c8a4c3045b17"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0.71810126, 0.28189877],\n",
              "        [0.7249614 , 0.27503857],\n",
              "        [0.7163054 , 0.28369457]], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "t1=time.time()\n",
        "m.run(output_names, {\"input\": im})\n",
        "print(time.time()-t1)\n",
        "\n",
        "#onnx model takes lesser time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3KiJBxi6qw5",
        "outputId": "10f57c96-94ad-47af-90c6-6a6e0e8515ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7529897689819336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy drop due to quantisation\n",
        "\n",
        "# def accuracy(model):\n",
        "#   total, acc = 0,0\n",
        "#   for im, label in validation_dataset:\n",
        "#     onnx_pred = model.run(output_names, {\"input\": np.array(im)})\n",
        "\n",
        "#     if(int(np.argmax(onnx_pred, axis = -1)[0][0]) == int(np.argmax(label, axis = -1)[0])):\n",
        "#       acc += 1\n",
        "\n",
        "#     total += 1\n",
        "#   return acc/total\n",
        "\n",
        "# providers=['CUDAExecutionProvider']\n",
        "# m = rt.InferenceSession(\"/content/drive/MyDrive/Bang/vit_keras.onnx\", providers=providers)\n",
        "# m_q = rt.InferenceSession(\"/content/vit_quantized.onnx\", providers=providers)\n",
        "# print(accuracy(m_q))\n",
        "# print(accuracy(m))\n",
        "\n",
        "# 0.9051799824407375\n",
        "# 0.9051799824407375"
      ],
      "metadata": {
        "id": "7Qn5_ksY7wck"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# QUAntisation Aware training"
      ],
      "metadata": {
        "id": "w--y1sG78em4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary() #here we have vgg16 as one model inside our model so we need to have one model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyDmUeSv9thL",
        "outputId": "c4bc456e-e822-43cf-d1db-77d8ae9cdea5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               3211392   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17942850 (68.45 MB)\n",
            "Trainable params: 3228162 (12.31 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=Flatten()(conv_base.output)\n",
        "x=Dense(128,activation='relu',kernel_initializer=initializer)(x)\n",
        "x=Dense(128,activation='relu',kernel_initializer=initializer)(x)\n",
        "x=Dense(2,activation='softmax',kernel_initializer=initializer)(x)\n",
        "\n",
        "model_new =keras.Model(inputs=conv_base.input, outputs= x)\n",
        "\n",
        "model_new.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrLBv7vM_H8W",
        "outputId": "a0abdb01-b8e9-4cbd-b7e4-5f7b5f74f51b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               3211392   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17942850 (68.45 MB)\n",
            "Trainable params: 17942850 (68.45 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_new.compile(\n",
        "    optimizer=tensorflow.keras.optimizers.SGD(learning_rate=0.001,momentum=0.9,nesterov=True,weight_decay=0.0005),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "import numpy as np\n",
        "X=np.random.normal(size=(10,224,224,3))\n",
        "y=np.array([1,0,1,1,0,0,1,1,0,0])\n",
        "\n",
        "history=model_new.fit(\n",
        "    X, y,\n",
        "    epochs=1,\n",
        "    batch_size=2\n",
        ")\n",
        "model_new.save('/content/simple_vgg16/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QwWArOutUSA",
        "outputId": "a8ea70a1-0761-47ad-f48e-058c27dfae3e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 28s 5s/step - loss: 1.0484 - accuracy: 0.4000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-model-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpZT10niByRX",
        "outputId": "7c1d8e32-8a39-4803-8a05-e74c63b829e0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/242.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we can select some layers that we want to quantised\n",
        "#layers like batchnorm, type cannot be normalised with this tf quantisation\n",
        "\n",
        "import tensorflow_model_optimization as tfmot\n",
        "input=keras.layers.Input(shape=(224,224,3), name='input')\n",
        "conv=keras.layers.Conv2D(32, kernel_size=3, activation='relu', name='conv_layer')(input)\n",
        "x=Flatten(name='flatten')(conv)\n",
        "x=Dense(128,activation='relu',kernel_initializer=initializer, name='l1')(x)\n",
        "x=Dense(128,activation='relu',kernel_initializer=initializer, name='l2')(x)\n",
        "x=Dense(2,activation='softmax',kernel_initializer=initializer, name='l3')(x)\n",
        "\n",
        "model_noob =keras.Model(inputs=input, outputs= x)"
      ],
      "metadata": {
        "id": "cdH7cBQr_9gj"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_noob.summary()"
      ],
      "metadata": {
        "id": "dcwoGU1wB97O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c585325c-6787-498d-e54c-ed5e4394045b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv_layer (Conv2D)         (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1577088)           0         \n",
            "                                                                 \n",
            " l1 (Dense)                  (None, 128)               201867392 \n",
            "                                                                 \n",
            " l2 (Dense)                  (None, 128)               16512     \n",
            "                                                                 \n",
            " l3 (Dense)                  (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 201885058 (770.13 MB)\n",
            "Trainable params: 201885058 (770.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quant_aware = tfmot.quantization.keras.quantize_model(model_noob)\n",
        "#this doesnot work"
      ],
      "metadata": {
        "id": "p5P9-KSKnxUn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we will select layer by layer which we want to be quantise aware\n",
        "def apply_quantization_to_conv(layer):\n",
        "  if \"conv\" in layer.name:\n",
        "    return tfmot.quantization.keras.quantize_annotate_layer(layer) #this for maarking which layer to make Q.A.\n",
        "  return layer"
      ],
      "metadata": {
        "id": "zhaGm5xgoA0r"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quant_aware_eff = tf.keras.models.clone_model(\n",
        "    model_new, clone_function=apply_quantization_to_conv\n",
        ") #this is for cloning model so that apply the function on convo layers to make them Q.A."
      ],
      "metadata": {
        "id": "Bp0SaZLDqfGs"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quant_aware_eff.summary() #we get something different can seee"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAVPezWfrASr",
        "outputId": "9a023572-9469-4d44-8f15-304f3b24d917"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " quantize_annotate_22 (Quan  (None, 224, 224, 64)      1792      \n",
            " tizeAnnotate)                                                   \n",
            "                                                                 \n",
            " quantize_annotate_23 (Quan  (None, 224, 224, 64)      36928     \n",
            " tizeAnnotate)                                                   \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " quantize_annotate_24 (Quan  (None, 112, 112, 128)     73856     \n",
            " tizeAnnotate)                                                   \n",
            "                                                                 \n",
            " quantize_annotate_25 (Quan  (None, 112, 112, 128)     147584    \n",
            " tizeAnnotate)                                                   \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " quantize_annotate_26 (Quan  (None, 56, 56, 256)       295168    \n",
            " tizeAnnotate)                                                   \n",
            "                                                                 \n",
            " quantize_annotate_27 (Quan  (None, 56, 56, 256)       590080    \n",
            " tizeAnnotate)                                                   \n",
            "                                                                 \n",
            " quantize_annotate_28 (Quan  (None, 56, 56, 256)       590080    \n",
            " tizeAnnotate)                                                   \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " quantize_annotate_29 (Quan  (None, 28, 28, 512)       1180160   \n",
            " tizeAnnotate)                                                   \n",
            "                                                                 \n",
            " quantize_annotate_30 (Quan  (None, 28, 28, 512)       2359808   \n",
            " tizeAnnotate)                                                   \n",
            "                                                                 \n",
            " quantize_annotate_31 (Quan  (None, 28, 28, 512)       2359808   \n",
            " tizeAnnotate)                                                   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " quantize_annotate_32 (Quan  (None, 14, 14, 512)       2359808   \n",
            " tizeAnnotate)                                                   \n",
            "                                                                 \n",
            " quantize_annotate_33 (Quan  (None, 14, 14, 512)       2359808   \n",
            " tizeAnnotate)                                                   \n",
            "                                                                 \n",
            " quantize_annotate_34 (Quan  (None, 14, 14, 512)       2359808   \n",
            " tizeAnnotate)                                                   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               3211392   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17942850 (68.45 MB)\n",
            "Trainable params: 3228162 (12.31 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now we can compile and train it as regular model\n",
        "\n",
        "quant_aware_eff.compile(\n",
        "    optimizer=tensorflow.keras.optimizers.SGD(learning_rate=0.001,momentum=0.9,nesterov=True,weight_decay=0.0005),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "import numpy as np\n",
        "X=np.random.normal(size=(10,224,224,3))\n",
        "y=np.array([1,0,1,1,0,0,1,1,0,0])\n",
        "\n",
        "history=quant_aware_eff.fit(\n",
        "    X, y,\n",
        "    epochs=5,\n",
        "    batch_size=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2VjdrfCrZMT",
        "outputId": "d935d48b-8f4c-4577-c811-677949d1b672"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "5/5 [==============================] - 7s 1s/step - loss: 1.5670 - accuracy: 0.4000\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 7s 1s/step - loss: 1.3473 - accuracy: 0.3000\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 5s 1s/step - loss: 1.4986 - accuracy: 0.3000\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.9739 - accuracy: 0.3000\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 5s 1s/step - loss: 1.0386 - accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#post training quantisation\n",
        "\n",
        "#doing quantisation on already trained model"
      ],
      "metadata": {
        "id": "LElCrEgesaNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "model_new=keras.models.load_model('/content/simple_vgg16')\n",
        "model_new.summary()"
      ],
      "metadata": {
        "id": "SLE7_9R7tECM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X=np.random.normal(size=(10,224,224,3))\n",
        "X=np.float32(X)\n",
        "y=np.array([1,0,1,1,0,0,1,1,0,0])"
      ],
      "metadata": {
        "id": "XrCtKV8O0B1n"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_new)\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT] #this we can refer to docs and these are attributes that we can\n",
        "#define that tell for which we want to optimize speed , memory etc\n",
        "\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8 #in this we define inference input and output type\n",
        "\n",
        "#for defining representation of data we make generator that give input values as static quant need some inputs\n",
        "#to find s and z\n",
        "def representative_data_gen():\n",
        "  for input_value,j in zip(X,y): #training_dataset.take(20):\n",
        "    yield [input_value.reshape(1,224,224,3)]\n",
        "\n",
        "converter.representative_dataset = representative_data_gen #if want to use dynamic quantisatn\n",
        "#then dont specify data geenrator here"
      ],
      "metadata": {
        "id": "zfGA1NL9tKDG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_model = converter.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZhQxc-HtMIO",
        "outputId": "4ed3c9cd-fbd9-4d82-ca3d-dae7b624404f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now we save conversion in tflite format\n",
        "\n",
        "import pathlib\n",
        "\n",
        "tflite_models_dir = pathlib.Path(\"/content/quantized_models/\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "tflite_model_file = tflite_models_dir/\"eff_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MB_qoUn0wJ1",
        "outputId": "2f033e29-58fe-45ff-bd62-c0c94449734c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18069424"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we get 17 mb model from 136mb model"
      ],
      "metadata": {
        "id": "VEZMAYcv2X2Y"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tflite runtime\n",
        "!pip3 install --extra-index-url https://google-coral.github.io/py-repo/ tflite_runtime\n",
        "\n",
        "#this is used to run tflite model on any small devices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znOUXSHY2xz-",
        "outputId": "193969ea-827b-45fc-a6a1-0c58eea76d69"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://google-coral.github.io/py-repo/\n",
            "Collecting tflite_runtime\n",
            "  Downloading tflite_runtime-2.14.0-cp310-cp310-manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.10/dist-packages (from tflite_runtime) (1.25.2)\n",
            "Installing collected packages: tflite_runtime\n",
            "Successfully installed tflite_runtime-2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tflite_runtime as tflite\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "#we dont need tensorflow in small devices only take small libraries to read images and all and use\n",
        "#tflite runtime to do inference"
      ],
      "metadata": {
        "id": "BrxiZBjE24EY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_image = cv2.imread(\"/content/dataset/Emotions Dataset/Emotions Dataset/train/happy/148266.jpg\")\n",
        "# test_image = cv2.resize(test_image, (CONFIGURATION[\"IM_SIZE\"] ,CONFIGURATION[\"IM_SIZE\"]))\n",
        "# test_image = np.expand_dims(test_image, axis = 0)\n",
        "#print(CONFIGURATION['CLASS_NAMES'][tf.argmax(pretrained_model(im), axis = -1).numpy()[0]])\n",
        "\n",
        "test_image=np.zeros((1,224,224,3), dtype='float32')"
      ],
      "metadata": {
        "id": "qlh1lVyx3Ni0"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tflite_runtime.interpreter as tflite\n",
        "interpreter = tflite.Interpreter(model_path=\"/content/quantized_models/eff_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()[0]\n",
        "output_details = interpreter.get_output_details()[0]\n",
        "print(input_details['dtype'])\n",
        "print(input_details['index'])\n",
        "\n",
        "# test_image = test_image.numpy().astype(input_details[\"dtype\"])\n",
        "test_image = test_image.astype(input_details[\"dtype\"]) #converting float32 to uint8\n",
        "\n",
        "interpreter.set_tensor(input_details[\"index\"], test_image) #set tensor\n",
        "interpreter.invoke() #then do inference\n",
        "\n",
        "output = interpreter.get_tensor(output_details[\"index\"])[0] #get tensor at the level of output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MU_5Rw64T8L",
        "outputId": "0e6b7fe3-40c6-4b42-c2c8-7a956584a183"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.uint8'>\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82j8gLE97kma",
        "outputId": "3961164e-d48d-414e-ac4d-5c237d3ec7c3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now measure accuracy of tflte quantised model\n",
        "# def accuracy(model_path):\n",
        "#   total, correct = 0,0\n",
        "#   interpreter = tf.lite.Interpreter(model_path=model_path) #here for checking val acc on system we are using lite from tf\n",
        "#   interpreter.allocate_tensors()\n",
        "\n",
        "#   input_details = interpreter.get_input_details()[0]\n",
        "#   output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "\n",
        "#   for im, label in validation_dataset:\n",
        "\n",
        "#     test_image = im.numpy().astype(input_details[\"dtype\"])\n",
        "\n",
        "#     interpreter.set_tensor(input_details[\"index\"], test_image)\n",
        "#     interpreter.invoke()\n",
        "#     output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
        "\n",
        "#     if(int(np.argmax(output)) == int(np.argmax(label, axis = -1)[0])):\n",
        "#       correct += 1\n",
        "\n",
        "#     total += 1\n",
        "#   return correct/total\n",
        "\n",
        "# accuracy(\"/content/drive/MyDrive/Bang/eff_model.tflite\")"
      ],
      "metadata": {
        "id": "VNAL6TCP8VoH"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "elxns5eI_G26"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}